{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "try:\n",
    "    sys.path.append(\n",
    "        glob.glob(\"../carla/dist/carla-*%d.%d-%s.egg\"\n",
    "            % (sys.version_info.major,sys.version_info.minor,\"win-amd64\" if os.name == \"nt\" else \"linux-x86_64\",))[0])\n",
    "except IndexError:\n",
    "    pass\n",
    "\n",
    "import carla\n",
    "\n",
    "CAMERA_POSITION =  [1.3, 0.0, 2.3]\n",
    "CAMERA_HEIGHT = 480\n",
    "CAMERA_WIDTH = 960\n",
    "CAMERA_FOV = 120\n",
    "CAMERA_LEFT = -60.0\n",
    "CAMERA_RIGHT = 60.0\n",
    "\n",
    "COMBINED_IMAGE_SHAPE = (160, 704, 3)\n",
    "\n",
    "MODEL_INPUT_SIZE = (10,) + COMBINED_IMAGE_SHAPE\n",
    "\n",
    "MODEL_OUTPUT_SIZE = (5,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('models/LTC_CNN3D_model-0.9464.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_img(image):\n",
    "    i = np.array(image.raw_data)\n",
    "    i2 = i.reshape((image.height, image.width, 4))\n",
    "    i3 = i2[:, :, :3]\n",
    "    \"\"\" cv2.imshow(\"\", i3)\n",
    "    cv2.waitKey(1) \"\"\"\n",
    "    return i3#/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_rgb_install():\n",
    "    camera_positions = [\n",
    "        carla.Transform(carla.Location(x=CAMERA_POSITION[0], z=CAMERA_POSITION[2]), carla.Rotation(yaw=CAMERA_LEFT)),  # Left\n",
    "        carla.Transform(carla.Location(x=CAMERA_POSITION[0], z=CAMERA_POSITION[2])),  # Center\n",
    "        carla.Transform(carla.Location(x=CAMERA_POSITION[0], z=CAMERA_POSITION[2]),carla.Rotation(yaw=CAMERA_RIGHT)),\n",
    "    ]  # Right\n",
    "\n",
    "    cameras = []\n",
    "    for camera_transform in camera_positions:\n",
    "        camera_blueprint = world.get_blueprint_library().find(\"sensor.camera.rgb\")\n",
    "        camera_blueprint.set_attribute(\"image_size_x\", str(CAMERA_WIDTH))\n",
    "        camera_blueprint.set_attribute(\"image_size_y\", str(CAMERA_HEIGHT))\n",
    "        camera_blueprint.set_attribute(\"fov\", str(CAMERA_FOV))\n",
    "        camera = world.spawn_actor(camera_blueprint, camera_transform, attach_to=ego_vehicle)\n",
    "        actor_list.append(camera)\n",
    "        cameras.append(camera)\n",
    "    return cameras\n",
    "\n",
    "\n",
    "def combine_images(images):\n",
    "    combined_image = np.zeros(COMBINED_IMAGE_SHAPE, dtype=np.float32)\n",
    "\n",
    "    return combined_image\n",
    "\n",
    "\n",
    "actor_list = []\n",
    "\n",
    "try:\n",
    "    client = carla.Client(\"localhost\", 2000)\n",
    "    client.set_timeout(3.0)\n",
    "\n",
    "    # Once we have a client we can retrieve the world that is currently running.\n",
    "    world = client.get_world()\n",
    "\n",
    "    # Retrieve the spectator object\n",
    "    spectator = world.get_spectator()\n",
    "\n",
    "    # Get the location and rotation of the spectator through its transform\n",
    "    transform = spectator.get_transform()\n",
    "\n",
    "    location = transform.location\n",
    "    rotation = transform.rotation\n",
    "\n",
    "    blueprint_library = world.get_blueprint_library()\n",
    "\n",
    "    # Set the spectator with an empty transform\n",
    "    # spectator.set_transform(carla.Transform())\n",
    "\n",
    "    # This will set the spectator at the origin of the map, with 0 degrees\n",
    "    # pitch, yaw and roll - a good way to orient yourself in the map\n",
    "\n",
    "    vehicle_blueprints = blueprint_library.filter(\"*vehicle*\")\n",
    "\n",
    "    spawn_points = world.get_map().get_spawn_points()\n",
    "\n",
    "  \n",
    "\n",
    "    ego_vehicle = world.spawn_actor(\n",
    "        blueprint_library.filter(\"etron\")[0], random.choice(spawn_points)\n",
    "    )\n",
    "    actor_list.append(ego_vehicle)\n",
    "    car_transform = ego_vehicle.get_transform()\n",
    "    spectator.set_transform(\n",
    "        carla.Transform(\n",
    "            carla.Location(\n",
    "                x=car_transform.location.x,\n",
    "                y=car_transform.location.y,\n",
    "                z=car_transform.location.z + 10,\n",
    "            ),\n",
    "            carla.Rotation(\n",
    "                pitch=-60,\n",
    "                yaw=car_transform.rotation.yaw,\n",
    "                roll=car_transform.rotation.roll,\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    \"\"\" for i in range(0, 50):\n",
    "        npc_vehicle = world.try_spawn_actor(\n",
    "            random.choice(vehicle_blueprints), random.choice(spawn_points)\n",
    "        )\n",
    "        if npc_vehicle is not None:\n",
    "            # npc_vehicle.set_autopilot(True)\n",
    "            actor_list.append(npc_vehicle) \"\"\"\n",
    "\n",
    "    \"\"\" postavljanje senzora na auto \"\"\"\n",
    "    # kamera RGB\n",
    "    camera_list = camera_rgb_install()\n",
    "\n",
    "    ego_vehicle.get_control().steer = 0.0\n",
    "    ego_vehicle.get_control().throttle = 0.0\n",
    "    ego_vehicle.get_control().brake = 0.0\n",
    "    ego_vehicle.get_control().hand_brake = False\n",
    "    ego_vehicle.get_control().reverse = False\n",
    "\n",
    "    seconds = 100\n",
    "\n",
    "    image_queue = []\n",
    "    camera_images = []\n",
    "    for frame in range(1):\n",
    "        for camera in camera_list:\n",
    "            camera.listen(lambda image: camera_images.append(process_img(image)))\n",
    "\n",
    "        time.sleep(1)\n",
    "        combined_image = np.hstack(\n",
    "            (camera_images[0], camera_images[1], camera_images[2])\n",
    "        )\n",
    "        cv2.imshow(\"\", combined_image)\n",
    "        cv2.waitKey(1)\n",
    "        image_queue.append(camera_images)\n",
    "        camera_images.clear()\n",
    "\n",
    "    \"\"\" for _ in range(seconds):\n",
    "        # Synchronize the CARLA world\n",
    "        world.tick()\n",
    "\n",
    "        image_queue = []\n",
    "        camera_images = []\n",
    "        for frame in range(10):\n",
    "            for camera in camera_list:\n",
    "                camera.listen(lambda image: camera_images.append(process_img(image)))\n",
    "            combined_image = np.hstack(\n",
    "                (camera_images[0], camera_images[1], camera_images[2])\n",
    "            )\n",
    "            cv2.imshow(\"\", combined_image)\n",
    "            cv2.waitKey(1)\n",
    "            image_queue.append(camera_images)\n",
    "\n",
    "        # Get car controls\n",
    "        control = ego_vehicle.get_control() \"\"\"\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "finally:\n",
    "    for actor in actor_list:\n",
    "        actor.destroy()\n",
    "    print(\"done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-directml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
